{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "795f2d68-d436-43cb-8100-6b008ef51685",
   "metadata": {},
   "source": [
    "# Agrega dados na Camada Silver com dados interessantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34a88e9c-f7b3-4217-bbf9-d9a354b44d37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informe a Twitter HashTag: #\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " gremio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json lido: 1000 registros\n",
      "Silver tweets.parquet atualizado\n",
      "parquet: 1000 registros\n",
      "+-------+\n",
      "|hashtag|\n",
      "+-------+\n",
      "| gremio|\n",
      "+-------+\n",
      "\n",
      "Bronze log_tweets.parquet atualizado\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as Func\n",
    "from pyspark.sql.functions import lit\n",
    "from datetime import datetime\n",
    "hoje = datetime.now().strftime(\"%Y_%m_%d-%I:%M:%S_%p\")\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Cria contexto Spark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('TwitterApp') \\\n",
    "    .config('spark.executor.memory', '4gb') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "contexto = spark.sparkContext\n",
    "sqlContext = SQLContext(contexto)\n",
    "\n",
    "# Estas variáveis serão passadas através de Parâmetros  (sys.argv[x])\n",
    "########################################\n",
    "print(\"informe a Twitter HashTag: #\")\n",
    "hashtag = input()\n",
    "desde = '2023-02-01'\n",
    "ate = '2023-02-10'\n",
    "########################################\n",
    "\n",
    "# Le arquivo json\n",
    "ambiente = \"/home/jovyan/work\"\n",
    "diretorio = '/data/brz/json/'\n",
    "file_json = f'{ambiente}{diretorio}{hashtag}-tweets.json'\n",
    "df = spark.read.json(file_json)\n",
    "\n",
    "print(f'json lido: {df.count()} registros')\n",
    "\n",
    "if df.count() > 0 :\n",
    "    df2 = df.withColumn('ano', Func.substring('date', 1 , 4).cast(\"int\"))\\\n",
    "      .withColumn('mes', Func.substring('date', 6 , 2).cast(\"int\"))\\\n",
    "      .withColumn('dia', Func.substring('date', 9 , 2).cast(\"int\"))\\\n",
    "      .withColumn(\"hashtaginformada\", lit(hashtag).cast(\"string\")) \\\n",
    "      .withColumn(\"retweetCount\",Func.col(\"retweetCount\").cast(\"int\")) \\\n",
    "      .withColumn(\"likeCount\",Func.col(\"likeCount\").cast(\"int\")) \n",
    "\n",
    "    df2.createOrReplaceTempView(\"tweets_view\");\n",
    "    #df2.printSchema()\n",
    "    sql = \"SELECT ano, mes, dia, hashtaginformada, \\\n",
    "        id, retweetCount, likeCount, lang, sourceLabel, \\\n",
    "        rawContent texto, date, hashtags,\\\n",
    "        user.location,  \\\n",
    "        user.displayname , user.username, user.followersCount, user.friendsCount  \\\n",
    "        FROM tweets_view \"\n",
    "\n",
    "    df_sql = spark.sql(sql);\n",
    "\n",
    "    #Gravar parquet\n",
    "    diretorio = '/data/brz/parquet/'\n",
    "    caminho_parquet = f'{ambiente}{diretorio}tweets.parquet'\n",
    "\n",
    "    try:\n",
    "        df_brz = sqlContext.read.parquet('../../data/brz/parquet/tweets.parquet')\n",
    "        df_sql.write.mode('append').parquet(caminho_parquet)\n",
    "        print('Silver tweets.parquet atualizado')\n",
    "    except:\n",
    "        #Gravar parquet - sempre overwrite\n",
    "        df_sql.write.mode('overwrite').parquet(caminho_parquet)\n",
    "        print('Silver tweets.parquet gerado')\n",
    "\n",
    "    v_qtd_registros = df.count()    \n",
    "    print(f'parquet: {df.count()} registros')\n",
    "    #df_show = spark.sql(\"SELECT hashtaginformada , count(*) as qtd  FROM tweets_view2 group by 1\");\n",
    "    #df_show.show()\n",
    "    #df_brz.count()\n",
    "\n",
    "else:\n",
    "    v_qtd_registros = 0    \n",
    "    print('Json vazio')\n",
    "    \n",
    "\n",
    "# Cria Log\n",
    "df2.createOrReplaceTempView(\"tweets_view\");\n",
    "\n",
    "df_log = spark.sql(\"SELECT DISTINCT hashtaginformada as hashtag FROM tweets_view\");\n",
    "df_log.show()\n",
    "\n",
    "if v_qtd_registros == 0:\n",
    "    df_log = df_log.withColumn('hashtag', lit(hashtag))\n",
    "    df_log.show() \n",
    "\n",
    "df_log2 = df_log.withColumn('desde', lit(desde))\\\n",
    "  .withColumn('ate', lit(ate))\\\n",
    "  .withColumn('data_execucao', lit(hoje))\\\n",
    "  .withColumn('qtd_registros', lit(v_qtd_registros ))\n",
    "\n",
    "diretorio = '/data/brz/parquet/'\n",
    "caminho_parquet = f'{ambiente}{diretorio}log_tweets.parquet'\n",
    "\n",
    "try:\n",
    "    df_brz = sqlContext.read.parquet('../../data/brz/parquet/log_tweets.parquet')\n",
    "    df_log2.write.mode('append').parquet(caminho_parquet)\n",
    "    print('Bronze log_tweets.parquet atualizado')\n",
    "except:\n",
    "    df_log2.write.mode('overwrite').parquet(caminho_parquet)\n",
    "    print('Bronze log_tweets.parquet gerado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660134a-935a-4fe4-ac2f-6da2ad526e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba1d293-385b-47ff-8d45-e8075b73535a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ano: integer (nullable = true)\n",
      " |-- mes: integer (nullable = true)\n",
      " |-- dia: integer (nullable = true)\n",
      " |-- hashtaginformada: string (nullable = false)\n",
      " |-- id: long (nullable = true)\n",
      " |-- retweetCount: integer (nullable = true)\n",
      " |-- likeCount: integer (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- sourceLabel: string (nullable = true)\n",
      " |-- texto: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- displayname: string (nullable = true)\n",
      " |-- username: string (nullable = true)\n",
      " |-- followersCount: long (nullable = true)\n",
      " |-- friendsCount: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b5f38-c92a-4a7f-b8d9-629f6c3d5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
